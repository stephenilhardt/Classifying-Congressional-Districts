{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers = pd.read_csv('sf1_numbers.csv')\n",
    "sf1_percentages = pd.read_csv('sf1_percentages.csv')\n",
    "acs1_numbers = pd.read_csv('acs1_numbers.csv')\n",
    "acs1_percentages = pd.read_csv('acs1_percentages.csv')\n",
    "social_numbers = pd.read_csv('social_numbers.csv')\n",
    "social_percentages = pd.read_csv('social_percentages.csv')\n",
    "economic_numbers = pd.read_csv('economic_numbers.csv')\n",
    "economic_percentages = pd.read_csv('economic_percentages.csv')\n",
    "housing_numbers = pd.read_csv('housing_numbers.csv')\n",
    "housing_percentages = pd.read_csv('housing_percentages.csv')\n",
    "\n",
    "predictions = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages,\n",
    "           social_numbers, social_percentages, economic_numbers,\n",
    "           economic_percentages, housing_numbers, housing_percentages]\n",
    "\n",
    "dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages]\n",
    "\n",
    "dfs_numbers = ['sf1_numbers', 'acs1_numbers', 'social_numbers', 'economic_numbers',\n",
    "              'housing_numbers']\n",
    "\n",
    "names = ['sf1_numbers', 'sf1_percentages', 'acs1_numbers',\n",
    "         'acs1_percentages','social_numbers','social_percentages',\n",
    "         'economic_numbers','economic_percentages','housing_numbers',\n",
    "         'housing_percentages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, df in enumerate(full_dfs):\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    df.name = names[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predictions.loc[:,'Democrat']\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbg = naive_bayes.GaussianNB()\n",
    "nbb = naive_bayes.BernoulliNB()\n",
    "nbm = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8358631288694657\n",
      "AUC Score: 0.7397058823529412 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5076691871470708\n",
      "AUC Score: 0.5 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7498278189320174\n",
      "AUC Score: 0.7380718954248365 \n",
      "\n",
      "sf1_percentages \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8396885954064665\n",
      "AUC Score: 0.7398692810457517 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.6837585205284284\n",
      "AUC Score: 0.6684640522875818 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7909569309209079\n",
      "AUC Score: 0.7323529411764707 \n",
      "\n",
      "acs1_numbers \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8809526343382437\n",
      "AUC Score: 0.7807189542483661 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5502991711789589\n",
      "AUC Score: 0.5859477124183007 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7803088128769414\n",
      "AUC Score: 0.7834967320261439 \n",
      "\n",
      "acs1_percentages \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8957296386564375\n",
      "AUC Score: 0.7622549019607843 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.625602524482437\n",
      "AUC Score: 0.5826797385620915 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.73978828204728\n",
      "AUC Score: 0.7287581699346405 \n",
      "\n",
      "social_numbers \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8855500762387292\n",
      "AUC Score: 0.7686274509803921 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5052441920495611\n",
      "AUC Score: 0.5 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7354092679080972\n",
      "AUC Score: 0.7254901960784315 \n",
      "\n",
      "social_percentages \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8870012414306467\n",
      "AUC Score: 0.782516339869281 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5045775253828945\n",
      "AUC Score: 0.5 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7264608421077907\n",
      "AUC Score: 0.7197712418300654 \n",
      "\n",
      "economic_numbers \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8544308900921667\n",
      "AUC Score: 0.7521241830065359 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5170856667186932\n",
      "AUC Score: 0.5089869281045751 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7757705986641213\n",
      "AUC Score: 0.7861111111111111 \n",
      "\n",
      "economic_percentages \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8619575760486328\n",
      "AUC Score: 0.7299019607843136 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.596904429850364\n",
      "AUC Score: 0.5475490196078431 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7376832078695977\n",
      "AUC Score: 0.7339869281045752 \n",
      "\n",
      "housing_numbers \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8742528228339997\n",
      "AUC Score: 0.7513071895424837 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.528157292704694\n",
      "AUC Score: 0.5800653594771241 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.8035386176177498\n",
      "AUC Score: 0.7807189542483661 \n",
      "\n",
      "housing_percentages \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.885562020706519\n",
      "AUC Score: 0.7477124183006536 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5562479107386552\n",
      "AUC Score: 0.5462418300653595 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7738376279149808\n",
      "AUC Score: 0.7418300653594772 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in full_dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    print(df.name,'\\n')\n",
    "    \n",
    "    nbg.fit(X_train, y_train)\n",
    "    \n",
    "    print('Gaussian Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(nbg,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, nbg.predict(X_test)),'\\n')\n",
    "    \n",
    "    nbb.fit(X_train, y_train)\n",
    "    \n",
    "    print('Bernoulli Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(nbb,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, nbb.predict(X_test)),'\\n')\n",
    "    \n",
    "    nbm.fit(X_train, y_train)\n",
    "    \n",
    "    print('Multinomial Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(nbm,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, nbm.predict(X_test)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "grid = GridSearchCV(rf, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9754959823590383\n",
      "sf1_numbers AUC Score: 0.9248366013071895\n",
      "sf1_numbers Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9728379864971405\n",
      "sf1_percentages AUC Score: 0.924673202614379\n",
      "sf1_percentages Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=11, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.9656753510783478\n",
      "acs1_numbers AUC Score: 0.8849673202614379\n",
      "acs1_numbers Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=16, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.9662904307388154\n",
      "acs1_percentages AUC Score: 0.8766339869281047\n",
      "acs1_percentages Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Depth\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "grid = GridSearchCV(dt, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9078037066829949\n",
      "sf1_numbers AUC Score: 0.9333333333333333\n",
      "sf1_numbers Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=16,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9320308460698035\n",
      "sf1_percentages AUC Score: 0.9014705882352941\n",
      "sf1_percentages Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.8876937764384308\n",
      "acs1_numbers AUC Score: 0.781045751633987\n",
      "acs1_numbers Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.8934850800206504\n",
      "acs1_percentages AUC Score: 0.8413398692810458\n",
      "acs1_percentages Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Depth\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear', max_iter=100000)\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], 'penalty': ['l1','l2']}\n",
    "\n",
    "grid = GridSearchCV(lr, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvm = LinearSVC(max_iter=100000)\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid = GridSearchCV(lvm, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
