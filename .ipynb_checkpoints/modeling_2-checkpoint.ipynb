{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers = pd.read_csv('sf1_numbers_short.csv')\n",
    "sf1_percentages = pd.read_csv('sf1_percentages_short.csv')\n",
    "\n",
    "acs1_numbers = pd.read_csv('acs1_numbers_short.csv')\n",
    "acs1_percentages = pd.read_csv('acs1_percentages_short.csv')\n",
    "\n",
    "social_numbers = pd.read_csv('social_numbers_short.csv')\n",
    "social_percentages = pd.read_csv('social_percentages_short.csv')\n",
    "\n",
    "economic_numbers = pd.read_csv('economic_numbers_short.csv')\n",
    "economic_percentages = pd.read_csv('economic_percentages_short.csv')\n",
    "\n",
    "housing_numbers = pd.read_csv('housing_numbers_short.csv')\n",
    "housing_percentages = pd.read_csv('housing_percentages_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages,\n",
    "           social_numbers, social_percentages, economic_numbers,\n",
    "           economic_percentages, housing_numbers, housing_percentages]\n",
    "\n",
    "dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages]\n",
    "\n",
    "dfs_numbers = ['sf1_numbers', 'acs1_numbers', 'social_numbers', 'economic_numbers',\n",
    "              'housing_numbers']\n",
    "\n",
    "names = ['sf1_numbers', 'sf1_percentages', 'acs1_numbers',\n",
    "         'acs1_percentages','social_numbers','social_percentages',\n",
    "         'economic_numbers','economic_percentages','housing_numbers',\n",
    "         'housing_percentages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in full_dfs:\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    \n",
    "predictions.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, df in enumerate(full_dfs):\n",
    "    df.name = names[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predictions.loc[:,'Democrat']\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "grid = GridSearchCV(rf, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9557031740123982\n",
      "sf1_numbers AUC Score: 0.9217320261437909\n",
      "sf1_numbers Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=16, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9606239849843721\n",
      "sf1_percentages AUC Score: 0.9215686274509804\n",
      "sf1_percentages Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=11, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.9225534531542025\n",
      "acs1_numbers AUC Score: 0.8047385620915032\n",
      "acs1_numbers Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.9258203239245537\n",
      "acs1_percentages AUC Score: 0.8352941176470589\n",
      "acs1_percentages Best Depth RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Depth\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "grid = GridSearchCV(dt, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9275086463923673\n",
      "sf1_numbers AUC Score: 0.930392156862745\n",
      "sf1_numbers Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=17,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9353956657982255\n",
      "sf1_percentages AUC Score: 0.930392156862745\n",
      "sf1_percentages Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=14,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.8620929656265381\n",
      "acs1_numbers AUC Score: 0.7753267973856209\n",
      "acs1_numbers Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.8684764516374319\n",
      "acs1_percentages AUC Score: 0.7978758169934641\n",
      "acs1_percentages Best Depth DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Depth\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbg = naive_bayes.GaussianNB()\n",
    "nbb = naive_bayes.BernoulliNB()\n",
    "nbm = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.7539096989270548\n",
      "AUC Score: 0.7192810457516341 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5\n",
      "AUC Score: 0.5 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.6845638992608245\n",
      "AUC Score: 0.6643790849673202 \n",
      "\n",
      "sf1_percentages \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.893437566283672\n",
      "AUC Score: 0.8034313725490196 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5708985228496075\n",
      "AUC Score: 0.5766339869281045 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.8752573051109964\n",
      "AUC Score: 0.7722222222222223 \n",
      "\n",
      "acs1_numbers \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8538940221632589\n",
      "AUC Score: 0.7807189542483661 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.5374782037274934\n",
      "AUC Score: 0.5704248366013072 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.7936862390094168\n",
      "AUC Score: 0.7928104575163398 \n",
      "\n",
      "acs1_percentages \n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Cross Val Score: 0.8842828124687342\n",
      "AUC Score: 0.8058823529411766 \n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "Cross Val Score: 0.6219215993724813\n",
      "AUC Score: 0.5442810457516339 \n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Cross Val Score: 0.8483130262173184\n",
      "AUC Score: 0.7918300653594772 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    print(df.name,'\\n')\n",
    "    \n",
    "    nbg.fit(X_train, y_train)\n",
    "    \n",
    "    print('Gaussian Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(nbg,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, nbg.predict(X_test)),'\\n')\n",
    "    \n",
    "    nbb.fit(X_train, y_train)\n",
    "    \n",
    "    print('Bernoulli Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(nbb,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, nbb.predict(X_test)),'\\n')\n",
    "    \n",
    "    nbm.fit(X_train, y_train)\n",
    "    \n",
    "    print('Multinomial Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(nbm,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, nbm.predict(X_test)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvm = LinearSVC()\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid = GridSearchCV(lvm, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.7864886458320827\n",
      "sf1_numbers AUC Score: 0.6934640522875817\n",
      "sf1_numbers Best Model LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.8854370796364555\n",
      "sf1_percentages AUC Score: 0.6647058823529411\n",
      "sf1_percentages Best Model LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.9144063704361816\n",
      "acs1_numbers AUC Score: 0.8179738562091503\n",
      "acs1_numbers Best Model LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.9148427297066911\n",
      "acs1_percentages AUC Score: 0.7898692810457517\n",
      "acs1_percentages Best Model LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid = GridSearchCV(svm, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9198838537977292\n",
      "sf1_numbers AUC Score: 0.8753267973856209\n",
      "sf1_numbers Best Model SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9340465236340061\n",
      "sf1_percentages AUC Score: 0.8866013071895424\n",
      "sf1_percentages Best Model SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.940284759858008\n",
      "acs1_numbers AUC Score: 0.8787581699346406\n",
      "acs1_numbers Best Model SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.9233167881283693\n",
      "acs1_percentages AUC Score: 0.5\n",
      "acs1_percentages Best Model SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], 'penalty': ['l1','l2']}\n",
    "\n",
    "grid = GridSearchCV(lr, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.7878251551788308\n",
      "sf1_numbers AUC Score: 0.7055555555555556\n",
      "sf1_numbers Best Model LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9010442768926616\n",
      "sf1_percentages AUC Score: 0.7929738562091503\n",
      "sf1_percentages Best Model LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.9169657778151301\n",
      "acs1_numbers AUC Score: 0.8122549019607843\n",
      "acs1_numbers Best Model LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.9183578914088357\n",
      "acs1_percentages AUC Score: 0.8320261437908496\n",
      "acs1_percentages Best Model LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {'n_neighbors': range(1,11)}\n",
    "\n",
    "grid = GridSearchCV(knn, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9251990002921484\n",
      "sf1_numbers AUC Score: 0.9238562091503268\n",
      "sf1_numbers Best Model KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9400242723303439\n",
      "sf1_percentages AUC Score: 0.9238562091503268\n",
      "sf1_percentages Best Model KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.9170514189208119\n",
      "acs1_numbers AUC Score: 0.8383986928104575\n",
      "acs1_numbers Best Model KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.9193383382758441\n",
      "acs1_percentages AUC Score: 0.8277777777777778\n",
      "acs1_percentages Best Model KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='uniform') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
