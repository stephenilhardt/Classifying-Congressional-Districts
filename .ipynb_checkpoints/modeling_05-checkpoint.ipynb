{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers = pd.read_csv('sf1_numbers_05.csv')\n",
    "sf1_percentages = pd.read_csv('sf1_percentages_05.csv')\n",
    "\n",
    "acs1_numbers = pd.read_csv('acs1_numbers_05.csv')\n",
    "acs1_percentages = pd.read_csv('acs1_percentages_05.csv')\n",
    "\n",
    "social_numbers = pd.read_csv('social_numbers_05.csv')\n",
    "social_percentages = pd.read_csv('social_percentages_05.csv')\n",
    "\n",
    "economic_numbers = pd.read_csv('economic_numbers_05.csv')\n",
    "economic_percentages = pd.read_csv('economic_percentages_05.csv')\n",
    "\n",
    "housing_numbers = pd.read_csv('housing_numbers_05.csv')\n",
    "housing_percentages = pd.read_csv('housing_percentages_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages,\n",
    "           social_numbers, social_percentages, economic_numbers,\n",
    "           economic_percentages, housing_numbers, housing_percentages]\n",
    "\n",
    "dfs = [sf1_numbers, social_numbers, economic_numbers, housing_numbers]\n",
    "\n",
    "dfs_numbers = ['sf1_numbers', 'acs1_numbers', 'social_numbers', 'economic_numbers',\n",
    "              'housing_numbers']\n",
    "\n",
    "names = ['sf1_numbers', 'sf1_percentages', 'acs1_numbers',\n",
    "         'acs1_percentages','social_numbers','social_percentages',\n",
    "         'economic_numbers','economic_percentages','housing_numbers',\n",
    "         'housing_percentages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in full_dfs:\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    \n",
    "predictions.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, df in enumerate(full_dfs):\n",
    "    df.name = names[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predictions.loc[:,'Democrat']\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "grid = GridSearchCV(rf, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9501512520360343\n",
      "sf1_numbers AUC Score: 0.9102941176470588\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-63cd4e0f86a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cross Val Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AUC Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Best Depth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    model = grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(model, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(df.name, \"Best Depth\", model.best_params_, '\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model.predict(X_test)) >= 0.8:\n",
    "        models['Random Forest {}'.format(df.name)] = model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "grid = GridSearchCV(dt, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    model = grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(model, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(df.name, \"Best Depth\", model.best_params_, '\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model.predict(X_test)) >= 0.8:\n",
    "        models['Decision Tree {}'.format(df.name)] = model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbg = naive_bayes.GaussianNB()\n",
    "nbb = naive_bayes.BernoulliNB()\n",
    "nbm = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    print(df.name,'\\n')\n",
    "    \n",
    "    model1 = nbg.fit(X_train, y_train)\n",
    "    \n",
    "    print('Gaussian Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(model1,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, model1.predict(X_test)),'\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model1.predict(X_test)) >= 0.8:\n",
    "        models['Gaussian Naive Bayes {}'.format(df.name)] = model1\n",
    "    \n",
    "    model2 = nbb.fit(X_train, y_train)\n",
    "    \n",
    "    print('Bernoulli Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(model2,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, model2.predict(X_test)),'\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model2.predict(X_test)) >= 0.8:\n",
    "        models['Gaussian Naive Bayes {}'.format(df.name)] = model2\n",
    "    \n",
    "    model3 = nbm.fit(X_train, y_train)\n",
    "    \n",
    "    print('Multinomial Naive Bayes')\n",
    "    print(\"Cross Val Score:\", np.mean(cross_val_score(model3,X_train,y_train,scoring='roc_auc',cv=kf)))\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, model3.predict(X_test)),'\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model3.predict(X_test)) >= 0.8:\n",
    "        models['Gaussian Naive Bayes {}'.format(df.name)] = model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma = 'scale')\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], 'kernel': ['rbf','linear']}\n",
    "\n",
    "grid = GridSearchCV(svm, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    model = grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(model, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", model.best_params_, '\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model.predict(X_test)) >= 0.8:\n",
    "        models['RBF SVM {}'.format(df.name)] = model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], 'penalty': ['l1','l2']}\n",
    "\n",
    "grid = GridSearchCV(lr, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    model = grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(model, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", model.best_params_, '\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model.predict(X_test)) >= 0.8:\n",
    "        models['Logistic Regression {}'.format(df.name)] = model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {'n_neighbors': range(1,11)}\n",
    "\n",
    "grid = GridSearchCV(knn, params, scoring='roc_auc', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "    \n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "    \n",
    "    model = grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(model, X_train, y_train, scoring='roc_auc',cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(df.name, \"Best Model\", model.best_params_, '\\n')\n",
    "    \n",
    "    if roc_auc_score(y_test, model.predict(X_test)) >= 0.8:\n",
    "        models['K Nearest Neighbor {}'.format(df.name)] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
