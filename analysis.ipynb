{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Stephen/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv('social_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('housing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic = pd.read_csv('economic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Stephen/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (75,76,77,78,79,81,83,85,87,105,106,223,224,225,226,227,228,229,230,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,485,523,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,575) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "acs1 = pd.read_csv('acs1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('results_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1 = pd.merge(acs1, results, how='right', on=['Year','District','State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1773"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1 = pd.merge(census, results, how='right',on = ['Year','District','State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.merge(social, results, how='right',on = ['Year','District','State'])\n",
    "economic = pd.merge(economic, results, how='right',on = ['Year','District','State'])\n",
    "housing = pd.merge(housing, results, how='right',on = ['Year','District','State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1 = sf1.dropna()\n",
    "acs1 = acs1.dropna()\n",
    "social = social.dropna()\n",
    "economic = economic.dropna()\n",
    "housing = housing.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1 = sf1.drop_duplicates()\n",
    "acs1 = acs1.drop_duplicates()\n",
    "social = social.drop_duplicates()\n",
    "economic = economic.drop_duplicates()\n",
    "housing = housing.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_predictions = sf1['Party']\n",
    "\n",
    "sf1_numeric_cols = []\n",
    "for column in sf1.columns:\n",
    "    try:\n",
    "        sf1[column] = pd.to_numeric(sf1[column])\n",
    "        sf1_numeric_cols.append(column)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "sf1_num = sf1[sf1_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_predictions = acs1['Party']\n",
    "\n",
    "acs1_numeric_cols = []\n",
    "for column in acs1.columns:\n",
    "    try:\n",
    "        acs1[column] = pd.to_numeric(acs1[column])\n",
    "        acs1_numeric_cols.append(column)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "acs1_num = acs1[acs1_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_predictions = social['Party']\n",
    "\n",
    "social_numeric_cols = []\n",
    "for column in social.columns:\n",
    "    try:\n",
    "        social[column] = pd.to_numeric(social[column])\n",
    "        social_numeric_cols.append(column)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "social_num = social[social_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic_predictions = economic['Party']\n",
    "\n",
    "economic_numeric_cols = []\n",
    "for column in economic.columns:\n",
    "    try:\n",
    "        economic[column] = pd.to_numeric(economic[column])\n",
    "        economic_numeric_cols.append(column)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "economic_num = economic[economic_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = housing['Party']\n",
    "\n",
    "housing_numeric_cols = []\n",
    "for column in housing.columns:\n",
    "    try:\n",
    "        housing[column] = pd.to_numeric(housing[column])\n",
    "        housing_numeric_cols.append(column)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "housing_num = housing[housing_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Stephen/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "sf1_num.drop(['Unnamed: 0_x', 'level_0','index','Id2','District','State','Year','Unnamed: 0_y'], axis=1, inplace=True)\n",
    "acs1_num.drop(['Unnamed: 0_x','index_x','Id2_x','Unnamed: 0_y','index','Id2','Year','District','State','index_y','Id2_y'], axis=1, inplace=True)\n",
    "social_num.drop(['Unnamed: 0_x','index','Id2','Year','District','State','Unnamed: 0_y'], axis=1, inplace=True)\n",
    "economic_num.drop(['Unnamed: 0_x','index','Id2','Year','District','State','Unnamed: 0_y'], axis=1, inplace=True)\n",
    "housing_num.drop(['Unnamed: 0_x','index','Id2','Year','District','State','Unnamed: 0_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747 361\n",
      "1747 636\n",
      "1747 170\n",
      "1747 238\n",
      "1747 228\n"
     ]
    }
   ],
   "source": [
    "print(len(sf1_num),len(sf1_num.columns))\n",
    "print(len(acs1_num),len(acs1_num.columns))\n",
    "print(len(social_num),len(social_num.columns))\n",
    "print(len(economic_num),len(economic_num.columns))\n",
    "print(len(housing_num),len(housing_num.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numerical = []\n",
    "sf1_percent = []\n",
    "\n",
    "for column in sf1_num:\n",
    "    if column[0] == 'N':\n",
    "        sf1_numerical.append(column)\n",
    "    elif column[0] == 'P':\n",
    "        sf1_percent.append(column)\n",
    "        \n",
    "acs1_numerical = []\n",
    "acs1_percent = []\n",
    "\n",
    "for column in acs1_num:\n",
    "    if column[0] == 'E':\n",
    "        acs1_numerical.append(column)\n",
    "    elif column[0] == 'P':\n",
    "        acs1_percent.append(column)\n",
    "        \n",
    "social_numerical = []\n",
    "social_percent = []\n",
    "\n",
    "for column in social_num:\n",
    "    if column[0] == 'E':\n",
    "        social_numerical.append(column)\n",
    "    elif column[0] == 'P':\n",
    "        social_percent.append(column)\n",
    "        \n",
    "economic_numerical = []\n",
    "economic_percent = []\n",
    "\n",
    "for column in economic_num:\n",
    "    if column[0] == 'E':\n",
    "        economic_numerical.append(column)\n",
    "    elif column[0] == 'P':\n",
    "        economic_percent.append(column)\n",
    "        \n",
    "housing_numerical = []\n",
    "housing_percent = []\n",
    "\n",
    "for column in housing_num:\n",
    "    if column[0] == 'E':\n",
    "        housing_numerical.append(column)\n",
    "    elif column[0] == 'P':\n",
    "        housing_percent.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers = sf1_num[sf1_numerical]\n",
    "sf1_percentages = sf1_num[sf1_percent]\n",
    "\n",
    "acs1_numbers = acs1_num[acs1_numerical]\n",
    "acs1_percentages = acs1_num[acs1_percent]\n",
    "\n",
    "social_numbers = social_num[social_numerical]\n",
    "social_percentages = social_num[social_percent]\n",
    "\n",
    "economic_numbers = economic_num[economic_numerical]\n",
    "economic_percentages = economic_num[economic_percent]\n",
    "\n",
    "housing_numbers = housing_num[housing_numerical]\n",
    "housing_percentages = housing_num[housing_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_predictions = pd.DataFrame(sf1_predictions)\n",
    "sf1_predictions[['Democrat','Republican']] = pd.get_dummies(sf1_predictions['Party'])\n",
    "\n",
    "acs1_predictions = pd.DataFrame(acs1_predictions)\n",
    "acs1_predictions[['Democrat','Republican']] = pd.get_dummies(acs1_predictions['Party'])\n",
    "\n",
    "social_predictions = pd.DataFrame(social_predictions)\n",
    "social_predictions[['Democrat','Republican']] = pd.get_dummies(social_predictions['Party'])\n",
    "\n",
    "economic_predictions = pd.DataFrame(economic_predictions)\n",
    "economic_predictions[['Democrat','Republican']] = pd.get_dummies(economic_predictions['Party'])\n",
    "\n",
    "housing_predictions = pd.DataFrame(housing_predictions)\n",
    "housing_predictions[['Democrat','Republican']] = pd.get_dummies(housing_predictions['Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sf1_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers.to_csv('sf1_numbers.csv')\n",
    "sf1_percentages.to_csv('sf1_percentages.csv')\n",
    "acs1_numbers.to_csv('acs1_numbers.csv')\n",
    "acs1_percentages.to_csv('acs1_percentages.csv')\n",
    "social_numbers.to_csv('social_numbers.csv')\n",
    "social_percentages.to_csv('social_percentages.csv')\n",
    "economic_numbers.to_csv('economic_numbers.csv')\n",
    "economic_percentages.to_csv('ec_percentages.csv')\n",
    "sf1_numbers.to_csv('sf1_numbers.csv')\n",
    "sf1_percentages.to_csv('sf1_percentages.csv')\n",
    "\n",
    "predictions.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbg = naive_bayes.GaussianNB()\n",
    "nbb = naive_bayes.BernoulliNB()\n",
    "nbm = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages, social_numbers, social_percentages, economic_numbers, economic_percentages, housing_numbers, housing_percentages]\n",
    "names = ['sf1_numbers', 'sf1_percentages', 'acs1_numbers', 'acs1_percentages', 'social_numbers', 'social_percentages', 'economic_numbers', 'economic_percentages', 'housing_numbers', 'housing_percentages']\n",
    "\n",
    "for index, df in enumerate(dfs):\n",
    "    df.name = names[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1747"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predictions.loc[:, 'Democrat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Gaussian Cross Val Score: 0.8358167413045827\n",
      "sf1_numbers Gaussian AUC Score: 0.7397058823529412 \n",
      "\n",
      "sf1_numbers Bernoulli Cross Val Score: 0.49923076923076926\n",
      "sf1_numbers Bernoulli AUC Score: 0.5 \n",
      "\n",
      "sf1_numbers Multinomial Cross Val Score: 0.7482934082513916\n",
      "sf1_numbers Multinomial AUC Score: 0.7380718954248365\n",
      "\n",
      "\n",
      "sf1_percentages Gaussian Cross Val Score: 0.839527149391891\n",
      "sf1_percentages Gaussian AUC Score: 0.7398692810457517 \n",
      "\n",
      "sf1_percentages Bernoulli Cross Val Score: 0.687159658706623\n",
      "sf1_percentages Bernoulli AUC Score: 0.6684640522875818 \n",
      "\n",
      "sf1_percentages Multinomial Cross Val Score: 0.7904993896899624\n",
      "sf1_percentages Multinomial AUC Score: 0.7410130718954249\n",
      "\n",
      "\n",
      "acs1_numbers Gaussian Cross Val Score: 0.8808268824562878\n",
      "acs1_numbers Gaussian AUC Score: 0.7807189542483661 \n",
      "\n",
      "acs1_numbers Bernoulli Cross Val Score: 0.5463581307304111\n",
      "acs1_numbers Bernoulli AUC Score: 0.5859477124183007 \n",
      "\n",
      "acs1_numbers Multinomial Cross Val Score: 0.7802700571890521\n",
      "acs1_numbers Multinomial AUC Score: 0.7834967320261439\n",
      "\n",
      "\n",
      "acs1_percentages Gaussian Cross Val Score: 0.8962300816814942\n",
      "acs1_percentages Gaussian AUC Score: 0.7622549019607843 \n",
      "\n",
      "acs1_percentages Bernoulli Cross Val Score: 0.6219018709504429\n",
      "acs1_percentages Bernoulli AUC Score: 0.5826797385620915 \n",
      "\n",
      "acs1_percentages Multinomial Cross Val Score: 0.7393790997826896\n",
      "acs1_percentages Multinomial AUC Score: 0.7287581699346405\n",
      "\n",
      "\n",
      "social_numbers Gaussian Cross Val Score: 0.8866128569313212\n",
      "social_numbers Gaussian AUC Score: 0.7686274509803921 \n",
      "\n",
      "social_numbers Bernoulli Cross Val Score: 0.5051467905696094\n",
      "social_numbers Bernoulli AUC Score: 0.5 \n",
      "\n",
      "social_numbers Multinomial Cross Val Score: 0.73659382966547\n",
      "social_numbers Multinomial AUC Score: 0.7254901960784315\n",
      "\n",
      "\n",
      "social_percentages Gaussian Cross Val Score: 0.8886093727613626\n",
      "social_percentages Gaussian AUC Score: 0.782516339869281 \n",
      "\n",
      "social_percentages Bernoulli Cross Val Score: 0.5044852521080709\n",
      "social_percentages Bernoulli AUC Score: 0.5 \n",
      "\n",
      "social_percentages Multinomial Cross Val Score: 0.7243153481968841\n",
      "social_percentages Multinomial AUC Score: 0.7197712418300654\n",
      "\n",
      "\n",
      "economic_numbers Gaussian Cross Val Score: 0.85639769322816\n",
      "economic_numbers Gaussian AUC Score: 0.7521241830065359 \n",
      "\n",
      "economic_numbers Bernoulli Cross Val Score: 0.5177674978889276\n",
      "economic_numbers Bernoulli AUC Score: 0.5089869281045751 \n",
      "\n",
      "economic_numbers Multinomial Cross Val Score: 0.7745264082153734\n",
      "economic_numbers Multinomial AUC Score: 0.7861111111111111\n",
      "\n",
      "\n",
      "economic_percentages Gaussian Cross Val Score: 0.8620703709484419\n",
      "economic_percentages Gaussian AUC Score: 0.7299019607843136 \n",
      "\n",
      "economic_percentages Bernoulli Cross Val Score: 0.5991994845381454\n",
      "economic_percentages Bernoulli AUC Score: 0.5475490196078431 \n",
      "\n",
      "economic_percentages Multinomial Cross Val Score: 0.738995042281479\n",
      "economic_percentages Multinomial AUC Score: 0.7339869281045752\n",
      "\n",
      "\n",
      "housing_numbers Gaussian Cross Val Score: 0.8752911126852441\n",
      "housing_numbers Gaussian AUC Score: 0.7513071895424837 \n",
      "\n",
      "housing_numbers Bernoulli Cross Val Score: 0.5263730767229753\n",
      "housing_numbers Bernoulli AUC Score: 0.5800653594771241 \n",
      "\n",
      "housing_numbers Multinomial Cross Val Score: 0.8050828524890644\n",
      "housing_numbers Multinomial AUC Score: 0.7777777777777778\n",
      "\n",
      "\n",
      "housing_percentages Gaussian Cross Val Score: 0.8859317661371977\n",
      "housing_percentages Gaussian AUC Score: 0.7477124183006536 \n",
      "\n",
      "housing_percentages Bernoulli Cross Val Score: 0.5568778515485866\n",
      "housing_percentages Bernoulli AUC Score: 0.5462418300653595 \n",
      "\n",
      "housing_percentages Multinomial Cross Val Score: 0.7737692027549995\n",
      "housing_percentages Multinomial AUC Score: 0.7418300653594772\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    nbg.fit(X_train, y_train)\n",
    "    print(df.name, 'Gaussian Cross Val Score:', np.mean(cross_val_score(nbg, X_train, y_train, scoring='roc_auc', cv=5)))\n",
    "    print(df.name, 'Gaussian AUC Score:', roc_auc_score(y_test, nbg.predict(X_test)),'\\n')\n",
    "    \n",
    "    nbb.fit(X_train, y_train)\n",
    "    print(df.name, 'Bernoulli Cross Val Score:', np.mean(cross_val_score(nbb, X_train, y_train, scoring='roc_auc', cv=5)))\n",
    "    print(df.name, 'Bernoulli AUC Score:', roc_auc_score(y_test, nbb.predict(X_test)),'\\n')\n",
    "    \n",
    "    nbm.fit(X_train, y_train)\n",
    "    print(df.name, 'Multinomial Cross Val Score:', np.mean(cross_val_score(nbm, X_train, y_train, scoring='roc_auc', cv=5)))\n",
    "    print(df.name, 'Multinomial AUC Score:', roc_auc_score(y_test, nbm.predict(X_test)))\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Gaussian Cross Val Score: 0.8342870682306612\n",
      "sf1_numbers Gaussian AUC Score: 0.7341503267973857 \n",
      "\n",
      "sf1_numbers Bernoulli Cross Val Score: 0.8020781901205811\n",
      "sf1_numbers Bernoulli AUC Score: 0.7428104575163399 \n",
      "\n",
      "\n",
      "\n",
      "acs1_numbers Gaussian Cross Val Score: 0.8801891320790961\n",
      "acs1_numbers Gaussian AUC Score: 0.7749999999999999 \n",
      "\n",
      "acs1_numbers Bernoulli Cross Val Score: 0.8718650050225515\n",
      "acs1_numbers Bernoulli AUC Score: 0.7856209150326797 \n",
      "\n",
      "\n",
      "\n",
      "social_numbers Gaussian Cross Val Score: 0.885095155539014\n",
      "social_numbers Gaussian AUC Score: 0.7715686274509804 \n",
      "\n",
      "social_numbers Bernoulli Cross Val Score: 0.8709794255481785\n",
      "social_numbers Bernoulli AUC Score: 0.7967320261437908 \n",
      "\n",
      "\n",
      "\n",
      "economic_numbers Gaussian Cross Val Score: 0.8565551764296263\n",
      "economic_numbers Gaussian AUC Score: 0.7521241830065359 \n",
      "\n",
      "economic_numbers Bernoulli Cross Val Score: 0.8197247593777639\n",
      "economic_numbers Bernoulli AUC Score: 0.7343137254901961 \n",
      "\n",
      "\n",
      "\n",
      "housing_numbers Gaussian Cross Val Score: 0.8744594485998889\n",
      "housing_numbers Gaussian AUC Score: 0.7485294117647059 \n",
      "\n",
      "housing_numbers Bernoulli Cross Val Score: 0.8764302865855853\n",
      "housing_numbers Bernoulli AUC Score: 0.7913398692810457 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_numbers = [sf1_numbers, acs1_numbers, social_numbers, economic_numbers, housing_numbers]\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "for df in dfs_numbers:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    X_train = scale.fit_transform(X_train)\n",
    "    X_test = scale.transform(X_test)\n",
    "    \n",
    "    nbg.fit(X_train, y_train)\n",
    "    print(df.name, 'Gaussian Cross Val Score:', np.mean(cross_val_score(nbg, X_train, y_train, scoring='roc_auc', cv=5)))\n",
    "    print(df.name, 'Gaussian AUC Score:', roc_auc_score(y_test, nbg.predict(X_test)),'\\n')\n",
    "    \n",
    "    nbb.fit(X_train, y_train)\n",
    "    print(df.name, 'Bernoulli Cross Val Score:', np.mean(cross_val_score(nbb, X_train, y_train, scoring='roc_auc', cv=5)))\n",
    "    print(df.name, 'Bernoulli AUC Score:', roc_auc_score(y_test, nbb.predict(X_test)),'\\n')\n",
    "    \n",
    "    #nbm.fit(X_train, y_train)\n",
    "    #print(df.name, 'Multinomial Cross Val Score:', np.mean(cross_val_score(nbm, X_train, y_train, scoring='roc_auc', cv=5)))\n",
    "    #print(df.name, 'Multinomial AUC Score:', roc_auc_score(y_test, nbm.predict(X_test)))\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9610843596547045\n",
      "sf1_numbers AUC Score: 0.9192810457516339\n",
      "sf1_numbers Best depth: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.9621971633589863\n",
      "sf1_percentages AUC Score: 0.8926470588235295\n",
      "sf1_percentages Best depth: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.9568572746955454\n",
      "acs1_numbers AUC Score: 0.8589869281045751\n",
      "acs1_numbers Best depth: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=18, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.9526480532110311\n",
      "acs1_percentages AUC Score: 0.8728758169934641\n",
      "acs1_percentages Best depth: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    grid = GridSearchCV(rf, params, scoring = 'roc_auc', cv=kf)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best depth:\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_numbers = ['sf1_numbers','acs1_numbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1')\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(lr, params, scoring = 'roc_auc', cv=kf)\n",
    "\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf1_numbers Cross Val Score: 0.9575756268184238\n",
      "sf1_numbers AUC Score: 0.8764705882352941\n",
      "sf1_numbers Best C: LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "sf1_percentages Cross Val Score: 0.954476028222337\n",
      "sf1_percentages AUC Score: 0.9047385620915033\n",
      "sf1_percentages Best C: LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "acs1_numbers Cross Val Score: 0.9551494183044987\n",
      "acs1_numbers AUC Score: 0.8931372549019608\n",
      "acs1_numbers Best C: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "acs1_percentages Cross Val Score: 0.940334247397678\n",
      "acs1_percentages AUC Score: 0.8960784313725492\n",
      "acs1_percentages Best C: LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    if df.name in dfs_numbers:\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_test = scale.transform(X_test)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(lr, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best C:\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [9,9,8,7]\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "#for index, df in enumerate(dfs):\n",
    "    \n",
    "X = sf1_numbers_m.loc[:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=9)\n",
    "model = rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Cross Val Score:\", np.mean(cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, model.predict(X_test)),'\\n')\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "import_columns = {}\n",
    "\n",
    "for f in range(10):\n",
    "    import_columns[f] = X_train.columns[indices[f]]\n",
    "\n",
    "pair_df = sf1_numbers_m[list(import_columns.values())]\n",
    "pair_df.columns = range(0,10)\n",
    "\n",
    "sns.pairplot(pair_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sf1_numbers.loc[:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=9)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Cross Val Score:\", np.mean(cross_val_score(rf, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "print(roc_auc_score(y_test, rf.predict(X_test)))\n",
    "sns.heatmap(confusion_matrix(y_test, rf.predict(X_test)), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sf1_numbers_m.columns))\n",
    "len(sf1_numbers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_m = sf1_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_columns = import_columns.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model = model\n",
    "max_df = sf1_numbers_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_max = sf1_numbers[list(max_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = sf1_max.loc[:]\n",
    "y = predictions.loc[:,'Democrat']\n",
    "    \n",
    "X = sf1_max.loc[:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=9)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Cross Val Score:\", np.mean(cross_val_score(rf, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, rf.predict(X_test)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_m = sf1_numbers_m.drop(sf1_numbers[[import_columns[i] for i in [3,2,9]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_m = sf1_numbers.copy()\n",
    "sf1_percentages_m = sf1_percentages.copy()\n",
    "acs1_numbers_m = acs1_numbers.copy()\n",
    "acs1_percentages_m = acs1_percentages.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importances)\n",
    "print(indices)\n",
    "for f in range(10):\n",
    "        print(\"{}. {} ({})\".format(f+1, X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [10, 10, 1, 1, 10, 1, 1, 1, 1, 1]\n",
    "\n",
    "for index, df in enumerate(dfs):\n",
    "    \n",
    "    X = df.loc[:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(C = cs[index])\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(rf, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, lr.predict(X_test)),'\\n')\n",
    "\n",
    "    coefs = lr.coef_\n",
    "\n",
    "    abs_coefs = np.abs(coefs)\n",
    "    indices = np.argsort(abs_coefs[0])[::-1]\n",
    "\n",
    "    print(\"Top 10 Features\\n\")\n",
    "\n",
    "    for f in range(10):\n",
    "        print(\"{}. {} ({})\".format(f+1, X.columns[indices[f]], coefs[0][indices[f]]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('Percent; HEALTH INSURANCE COVERAGE - With health insurance coverage - With private health insurance',\n",
    "            'Percent; HEALTH INSURANCE COVERAGE - With health insurance coverage - With public coverage',data=economic_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = sf1_numbers[['Number; SEX AND AGE - Male population - Under 5 years', 'Number; SEX AND AGE - Female population - 10 to 14 years',\n",
    "                   'Number; SEX AND AGE - Female population - Under 5 years']]\n",
    "\n",
    "pair.columns = ['Male < 5','Female 10-14','Female < 5']\n",
    "plt.figure(figsize=(100,100))\n",
    "sns.pairplot(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = sf1_percentages[['Percent; SEX AND AGE - Female population - 20 to 24 years', 'Percent; SEX AND AGE - Female population - 21 years and over',\n",
    "                   'Percent; SEX AND AGE - Total population - 20 to 24 years']]\n",
    "\n",
    "pair.columns = ['Female < 20-24','Female > 21','Total 20-24']\n",
    "sns.pairplot(pair);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear','rbf','poly']}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    X = df.loc[:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    scale = StandardScaler()\n",
    "    \n",
    "    X_train = scale.fit_transform(X_train)\n",
    "    X_test = scale.transform(X_test)\n",
    "    \n",
    "    grid = GridSearchCV(svm, params, scoring = 'roc_auc', cv=kf)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "    print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "    print(df.name, \"Best model:\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [sf1_numbers, sf1_percentages, acs1_numbers, acs1_percentages, social_numbers, social_percentages, economic_numbers, economic_percentages,\n",
    "      housing_numbers, housing_percentages]\n",
    "\n",
    "for df in dfs:\n",
    "    df.drop(['Democrat'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_with_predictions = sf1_numbers\n",
    "sf1_numbers_with_predictions['Democrat'] = predictions.Democrat\n",
    "\n",
    "sf1_percentages_with_predictions = sf1_percentages\n",
    "sf1_percentages_with_predictions['Democrat'] = predictions.Democrat\n",
    "\n",
    "acs1_numbers_with_predictions = acs1_numbers\n",
    "acs1_numbers_with_predictions['Democrat'] = predictions.Democrat\n",
    "\n",
    "acs1_percentages_with_predictions = acs1_percentages\n",
    "acs1_percentages_with_predictions['Democrat'] = predictions.Democrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_with_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_corr = sf1_numbers_with_predictions.corr()\n",
    "sf1_percentages_corr = sf1_percentages_with_predictions.corr()\n",
    "acs1_numbers_corr = acs1_numbers_with_predictions.corr()\n",
    "acs1_percentages_corr = acs1_percentages_with_predictions.corr()\n",
    "\n",
    "\n",
    "dfs_corr = [sf1_numbers_corr,sf1_percentages_corr,acs1_numbers_corr,acs1_percentages_corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sf1_numbers_with_predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Columns'] = sf1_numbers.columns\n",
    "df['Rows'] = sf1_numbers.columns[0]\n",
    "\n",
    "df['corr'] = sf1_numbers_corr.lookup(df['Rows'], df['Columns'])\n",
    "df['row_predicted'] = df['Rows'].corr(predictions['Democrat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif_(X, thresh=5.0):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
    "                  '\\' at index: ' + str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X.iloc[:, variables]\n",
    "\n",
    "sf1_numbers_dropped = calculate_vif_(sf1_numbers, thresh=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sf1_numbers_dropped.loc[:,:]\n",
    "y = predictions.loc[:,'Democrat']\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_dropped = df.loc[:]\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "grid = GridSearchCV(rf, params, scoring = 'roc_auc', cv=kf)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "print(df.name, \"Best depth:\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numbers_dropped = df.loc[:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "grid = GridSearchCV(lr, params, scoring = 'roc_auc', cv=kf)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(df.name, \"Cross Val Score:\", np.mean(cross_val_score(grid, X_train, y_train, scoring='roc_auc', cv=kf)))\n",
    "print(df.name, \"AUC Score:\", roc_auc_score(y_test, grid.predict(X_test)))\n",
    "print(df.name, \"Best depth:\", grid.best_estimator_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params = {'max_depth': range(1,21)}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_best.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf_best.estimators_],axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print(\"Top 10 Features\")\n",
    "    \n",
    "    for f in range(10):\n",
    "        print(\"{}. {} ({})\".format(f+1, X_train.columns[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acs1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_predictions = sf1['Party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_numeric_cols = []\n",
    "for column in sf1.columns:\n",
    "    try:\n",
    "        sf1[column] = pd.to_numeric(sf1[column])\n",
    "        sf1_numeric_cols.append(column)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_numeric_cols = []\n",
    "for column in acs1.columns:\n",
    "    try:\n",
    "        acs1[column] = pd.to_numeric(acs1[column])\n",
    "        acs1_numeric_cols.append(column)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_num = sf1[sf1_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_num = acs1[acs1_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_num.drop(['Unnamed: 0_x', 'level_0','index','Id2','District','State','Year','Unnamed: 0_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acs1_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_num.drop(['Unnamed: 0_x','index_x','Id2_x','Unnamed: 0_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_predictions = acs1['Party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_predictions = pd.DataFrame(acs1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_predictions[['Democrat','Republican']] = pd.get_dummies(acs1_predictions['Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_predictions = pd.DataFrame(sf1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_predictions[['Democrat','Republican']] = pd.get_dummies(sf1_predictions['Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = acs1_num.iloc[:]\n",
    "y = acs1_predictions.loc[:,'Democrat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "output = classification_report(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_predictions = pd.DataFrame(sf1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_predictions[['Democrat','Republican']] = pd.get_dummies(sf1_predictions['Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_numerical = []\n",
    "acs1_percent = []\n",
    "\n",
    "for column in acs1_num:\n",
    "    if column[0] == 'E':\n",
    "        acs1_numerical.append(column)\n",
    "    elif column[0] == 'P':\n",
    "        acs1_percent.append(column)\n",
    "        \n",
    "sf1_numerical = []\n",
    "sf1_percent = []\n",
    "\n",
    "for column in sf1_num:\n",
    "    if column[0] == 'N':\n",
    "        sf1_numerical.append(column)\n",
    "    elif column[0] == 'P':\n",
    "        sf1_percent.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sf1_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_num_e = sf1_num[sf1_numerical]\n",
    "sf1_num_p = sf1_num[sf1_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs1_num_e = acs1_num[acs1_numerical]\n",
    "acs1_num_p = acs1_num[acs1_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(forest, [{'max_depth':list(range(1,21))}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = acs1_num_e.iloc[:]\n",
    "y = acs1_predictions['Democrat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "mod = nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as to_pickle:\n",
    "    pickle.dump(mod, to_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, grid.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,100))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices])\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = gr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in gr.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,100))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices])\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(X_train.columns[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = acs1_num_p.iloc[:]\n",
    "y = acs1_predictions['Democrat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_train, nb.predict(X_train)))\n",
    "roc_auc_score(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sf1_num_p.iloc[:]\n",
    "y = sf1_predictions['Democrat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "importances\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,100))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices])\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sf1_num_e.iloc[:]\n",
    "y = sf1_predictions['Democrat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "importances\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,100))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices])\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, X_train.columns[indices[f]], X_train.columns[indices[f]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,100))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices])\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
